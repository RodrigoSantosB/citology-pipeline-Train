{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de Lesões Cervicais com MobileNet\n",
    "\n",
    "Este notebook implementa um pipeline completo para classificar imagens de citologia em LSIL (Lesão de Baixo Grau) e HSIL (Lesão de Alto Grau) usando transfer learning com MobileNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# Scikit-learn para métricas\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configurações\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Parâmetros do modelo\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_FASE1 = 10\n",
    "EPOCHS_FASE2 = 20\n",
    "INITIAL_LR = 1e-4\n",
    "FINE_TUNE_LR = 1e-5\n",
    "\n",
    "print(\"Configurações e imports concluídos!\")\n",
    "print(f\"TensorFlow versão: {tf.__version__}\")\n",
    "print(f\"GPU disponível: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparação e Reorganização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir caminhos\n",
    "BASE_DIR = Path(\"c:/Users/IA/Desktop/Dataset Citologia\")\n",
    "TILE_DIR = BASE_DIR / \"Tile\"\n",
    "PROCESSED_DIR = BASE_DIR / \"dataset_processado\"\n",
    "\n",
    "# Criar estrutura de diretórios processados\n",
    "for split in [\"train\", \"validation\"]:\n",
    "    for class_name in [\"LSIL\", \"HSIL\"]:\n",
    "        (PROCESSED_DIR / split / class_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Estrutura de diretórios criada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir mapeamento de categorias para classes\n",
    "# Baseado na análise do PDF\n",
    "LSIL_CATEGORIES = [\n",
    "    \"light_dysplastic\",\n",
    "    \"im_Dyskeratotic\",\n",
    "    \"im_Koilocytotic\",\n",
    "    \"Low squamous intra-epithelial lesion\"\n",
    "]\n",
    "\n",
    "HSIL_CATEGORIES = [\n",
    "    \"moderate_dysplastic\",\n",
    "    \"severe_dysplastic\",\n",
    "    \"carcinoma_in_situ\",\n",
    "    \"High squamous intra-epithelial lesion\",\n",
    "    \"Squamous cell carcinoma\"\n",
    "]\n",
    "\n",
    "# Categorias a serem ignoradas (Normal/Benigno)\n",
    "IGNORE_CATEGORIES = [\n",
    "    \"im_Metaplastic\",\n",
    "    \"im_Parabasal\",\n",
    "    \"im_Superficial-Intermediate\",\n",
    "    \"Negative for Intraepithelial malignancy\"\n",
    "]\n",
    "\n",
    "print(\"Mapeamento de categorias definido!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_images(tile_dir, lsil_categories, hsil_categories, ignore_categories):\n",
    "    \"\"\"Coletar todas as imagens e suas respectivas classes\"\"\"\n",
    "    images = []\n",
    "    \n",
    "    # Percorrer estrutura de diretórios\n",
    "    for class_dir in [\"HISIL\", \"LISIL\"]:\n",
    "        class_path = tile_dir / class_dir\n",
    "        \n",
    "        if not class_path.exists():\n",
    "            continue\n",
    "            \n",
    "        for dataset_dir in class_path.iterdir():\n",
    "            if dataset_dir.is_dir():\n",
    "                for category_dir in dataset_dir.iterdir():\n",
    "                    if category_dir.is_dir():\n",
    "                        category_name = category_dir.name\n",
    "                        \n",
    "                        # Determinar classe final\n",
    "                        if category_name in lsil_categories:\n",
    "                            final_class = \"LSIL\"\n",
    "                        elif category_name in hsil_categories:\n",
    "                            final_class = \"HSIL\"\n",
    "                        elif category_name in ignore_categories:\n",
    "                            print(f\"Ignorando categoria: {category_name}\")\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(f\"Categoria não mapeada: {category_name}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Coletar todas as imagens desta categoria\n",
    "                        for img_file in category_dir.glob(\"*\"):\n",
    "                            if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "                                images.append({\n",
    "                                    'path': str(img_file),\n",
    "                                    'original_class': class_dir,\n",
    "                                    'category': category_name,\n",
    "                                    'final_class': final_class\n",
    "                                })\n",
    "    \n",
    "    return images\n",
    "\n",
    "# Coletar imagens\n",
    "all_images = collect_images(TILE_DIR, LSIL_CATEGORIES, HSIL_CATEGORIES, IGNORE_CATEGORIES)\n",
    "print(f\"Total de imagens coletadas: {len(all_images)}\")\n",
    "\n",
    "# Criar DataFrame para análise\n",
    "df_images = pd.DataFrame(all_images)\n",
    "print(\"\\nDistribuição por classe final:\")\n",
    "print(df_images['final_class'].value_counts())\n",
    "print(\"\\nDistribuição por categoria:\")\n",
    "print(df_images['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dados em treino e validação\n",
    "train_df, val_df = train_test_split(\n",
    "    df_images, \n",
    "    test_size=0.2, \n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=df_images['final_class']\n",
    ")\n",
    "\n",
    "print(f\"Imagens de treino: {len(train_df)}\")\n",
    "print(f\"Imagens de validação: {len(val_df)}\")\n",
    "print(f\"\\nDistribuição no treino:\")\n",
    "print(train_df['final_class'].value_counts())\n",
    "print(f\"\\nDistribuição na validação:\")\n",
    "print(val_df['final_class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiar imagens para estrutura processada\n",
    "def copy_images_to_structure(df, split_name):\n",
    "    \"\"\"Copiar imagens para a estrutura de diretórios processada\"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        src_path = Path(row['path'])\n",
    "        dst_dir = PROCESSED_DIR / split_name / row['final_class']\n",
    "        dst_path = dst_dir / src_path.name\n",
    "        \n",
    "        if src_path.exists():\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "    \n",
    "    print(f\"Imagens copiadas para {split_name}\")\n",
    "\n",
    "# Copiar imagens\n",
    "copy_images_to_structure(train_df, \"train\")\n",
    "copy_images_to_structure(val_df, \"validation\")\n",
    "\n",
    "# Verificar estrutura final\n",
    "print(\"\\nEstrutura final do dataset processado:\")\n",
    "for split in [\"train\", \"validation\"]:\n",
    "    for class_name in [\"LSIL\", \"HSIL\"]:\n",
    "        path = PROCESSED_DIR / split / class_name\n",
    "        count = len(list(path.glob(\"*\")))\n",
    "        print(f\"{split}/{class_name}: {count} imagens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualização das Imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def show_sample_images(class_name, num_samples=4):\n",
    "    \"\"\"Mostrar amostras de imagens de uma classe\"\"\"\n",
    "    train_path = PROCESSED_DIR / \"train\" / class_name\n",
    "    image_files = list(train_path.glob(\"*\"))[:num_samples]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 4))\n",
    "    \n",
    "    for i, img_path in enumerate(image_files):\n",
    "        img = Image.open(img_path)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"{class_name} - {img_path.name}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Amostras de {class_name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar amostras\n",
    "show_sample_images(\"LSIL\", 4)\n",
    "show_sample_images(\"HSIL\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Criação dos Geradores de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar geradores de dados com aumento de dados para treino\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Gerador de dados para validação (apenas redimensionamento e normalização)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Criar geradores\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    PROCESSED_DIR / \"train\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    PROCESSED_DIR / \"validation\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(\"Geradores de dados criados!\")\n",
    "print(f\"Classes: {train_generator.class_indices}\")\n",
    "print(f\"Passos por época (treino): {len(train_generator)}\")\n",
    "print(f\"Passos por época (validação): {len(validation_generator)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Construção do Modelo MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mobilenet_model(input_shape=IMG_SIZE + (3,), num_classes=1):\n",
    "    \"\"\"Criar modelo MobileNetV2 com transfer learning\"\"\"\n",
    "    \n",
    "    # Carregar MobileNetV2 pré-treinado (sem o topo)\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Congelar as camadas da base\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Adicionar camadas customizadas\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Criar modelo\n",
    "model, base_model = create_mobilenet_model()\n",
    "\n",
    "# Compilar modelo\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=INITIAL_LR),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall()]\n",
    ")\n",
    "\n",
    "print(\"Modelo criado e compilado!\")\n",
    "print(f\"Número total de camadas: {len(model.layers)}\")\n",
    "print(f\"Camadas congeladas: {sum(1 for layer in base_model.layers if not layer.trainable)}\")\n",
    "print(f\"Camadas treináveis: {sum(1 for layer in model.layers if layer.trainable)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resumo do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fase 1: Treinamento do Topo Customizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks para o treinamento\n",
    "checkpoint_path = BASE_DIR / \"best_model_fase1.h5\"\n",
    "\n",
    "callbacks_fase1 = [\n",
    "    ModelCheckpoint(\n",
    "        str(checkpoint_path),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Iniciando Fase 1: Treinamento do topo customizado...\")\n",
    "\n",
    "history_fase1 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=EPOCHS_FASE1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=callbacks_fase1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Fase 1 concluída!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualização do Progresso da Fase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, title=\"Histórico de Treinamento\"):\n",
    "    \"\"\"Plotar histórico de treinamento\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Plotar perda\n",
    "    ax1.plot(history.history['loss'], label='Perda de Treino')\n",
    "    ax1.plot(history.history['val_loss'], label='Perda de Validação')\n",
    "    ax1.set_title(f'{title} - Perda')\n",
    "    ax1.set_xlabel('Época')\n",
    "    ax1.set_ylabel('Perda')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plotar acurácia\n",
    "    ax2.plot(history.history['accuracy'], label='Acurácia de Treino')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Acurácia de Validação')\n",
    "    ax2.set_title(f'{title} - Acurácia')\n",
    "    ax2.set_xlabel('Época')\n",
    "    ax2.set_ylabel('Acurácia')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history_fase1, \"Fase 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fase 2: Fine-tuning do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descongelar as últimas camadas da base para fine-tuning\n",
    "base_model.trainable = True\n",
    "\n",
    "# Congelar as primeiras camadas (manter early layers congeladas)\n",
    "fine_tune_at = 100  # Descongelar a partir da camada 100\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompilar com taxa de aprendizado menor\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=FINE_TUNE_LR),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall()]\n",
    ")\n",
    "\n",
    "print(f\"Fine-tuning: {len([l for l in base_model.layers if l.trainable])} camadas treináveis\")\n",
    "print(f\"Camadas congeladas: {len([l for l in base_model.layers if not l.trainable])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks para fine-tuning\n",
    "checkpoint_path_fase2 = BASE_DIR / \"best_model_fase2.h5\"\n",
    "\n",
    "callbacks_fase2 = [\n",
    "    ModelCheckpoint(\n",
    "        str(checkpoint_path_fase2),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=8,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Iniciando Fase 2: Fine-tuning...\")\n",
    "\n",
    "history_fase2 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=EPOCHS_FASE2,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=callbacks_fase2,\n",
    "    initial_epoch=EPOCHS_FASE1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Fase 2 concluída!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualização do Progresso Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar históricos\n",
    "def combine_histories(history1, history2):\n",
    "    \"\"\"Combinar históricos de duas fases de treinamento\"\"\"\n",
    "    combined = {}\n",
    "    \n",
    "    for key in history1.history.keys():\n",
    "        combined[key] = history1.history[key] + history2.history[key]\n",
    "    \n",
    "    return combined\n",
    "\n",
    "combined_history = combine_histories(history_fase1, history_fase2)\n",
    "\n",
    "# Criar objeto mock para plotagem\n",
    "class MockHistory:\n",
    "    def __init__(self, history_dict):\n",
    "        self.history = history_dict\n",
    "\n",
    "full_history = MockHistory(combined_history)\n",
    "plot_training_history(full_history, \"Treinamento Completo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar modelo no conjunto de validação\n",
    "print(\"Avaliando modelo no conjunto de validação...\")\n",
    "\n",
    "val_loss, val_accuracy, val_precision, val_recall = model.evaluate(\n",
    "    validation_generator,\n",
    "    steps=len(validation_generator),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\nResultados da Validação:\")\n",
    "print(f\"Perda: {val_loss:.4f}\")\n",
    "print(f\"Acurácia: {val_accuracy:.4f}\")\n",
    "print(f\"Precisão: {val_precision:.4f}\")\n",
    "print(f\"Recall: {val_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter predições\n",
    "print(\"Obtendo predições...\")\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_pred_proba = []\n",
    "\n",
    "for i in range(len(validation_generator)):\n",
    "    batch_X, batch_y = validation_generator[i]\n",
    "    predictions = model.predict(batch_X, verbose=0)\n",
    "    \n",
    "    y_true.extend(batch_y)\n",
    "    y_pred_proba.extend(predictions.flatten())\n",
    "    y_pred.extend((predictions > 0.5).astype(int).flatten())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "print(f\"Predições obtidas: {len(y_pred)} amostras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relatório de classificação\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['LSIL', 'HSIL']))\n",
    "\n",
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(f\"\\nMatriz de Confusão:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar matriz de confusão\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['LSIL', 'HSIL'], \n",
    "            yticklabels=['LSIL', 'HSIL'])\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.ylabel('Classe Verdadeira')\n",
    "plt.xlabel('Classe Predita')\n",
    "plt.show()\n",
    "\n",
    "# Calcular métricas adicionais\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)  # Same as recall\n",
    "\n",
    "print(f\"\\nMétricas Adicionais:\")\n",
    "print(f\"Especificidade: {specificity:.4f}\")\n",
    "print(f\"Sensibilidade (Recall): {sensitivity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Área sob a curva ROC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Salvamento do Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar modelo final\n",
    "final_model_path = BASE_DIR / \"modelo_cervical_cancer_final.h5\"\n",
    "model.save(str(final_model_path))\n",
    "\n",
    "# Salvar também em formato SavedModel\n",
    "savedmodel_path = BASE_DIR / \"modelo_cervical_cancer_savedmodel\"\n",
    "model.save(str(savedmodel_path))\n",
    "\n",
    "print(f\"Modelo salvo em: {final_model_path}\")\n",
    "print(f\"Modelo também salvo em formato SavedModel: {savedmodel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Teste de Predição em Nova Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para predizer uma nova imagem\n",
    "def predict_image(image_path, model, threshold=0.5):\n",
    "    \"\"\"Predizer classe de uma nova imagem\"\"\"\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    \n",
    "    # Carregar e pré-processar imagem\n",
    "    img = image.load_img(image_path, target_size=IMG_SIZE)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0\n",
    "    \n",
    "    # Fazer predição\n",
    "    prediction = model.predict(img_array, verbose=0)\n",
    "    probability = prediction[0][0]\n",
    "    \n",
    "    # Determinar classe\n",
    "    predicted_class = 'HSIL' if probability > threshold else 'LSIL'\n",
    "    confidence = probability if predicted_class == 'HSIL' else 1 - probability\n",
    "    \n",
    "    return predicted_class, confidence, probability\n",
    "\n",
    "# Testar com uma imagem de exemplo\n",
    "test_image_path = list((PROCESSED_DIR / \"validation\" / \"HSIL\").glob(\"*\"))[0]\n",
    "predicted_class, confidence, raw_prob = predict_image(test_image_path, model)\n",
    "\n",
    "print(f\"Imagem: {test_image_path.name}\")\n",
    "print(f\"Classe predita: {predicted_class}\")\n",
    "print(f\"Confiança: {confidence:.3f}\")\n",
    "print(f\"Probabilidade bruta (HSIL): {raw_prob:.3f}\")\n",
    "\n",
    "# Mostrar imagem\n",
    "img = Image.open(test_image_path)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Predição: {predicted_class} (Confiança: {confidence:.3f})\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Resumo e Conclusões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar resumo do treinamento\n",
    "summary = {\n",
    "    'Dataset': {\n",
    "        'Total de imagens': len(df_images),\n",
    "        'Imagens de treino': len(train_df),\n",
    "        'Imagens de validação': len(val_df),\n",
    "        'Classes': list(train_generator.class_indices.keys())\n",
    "    },\n",
    "    'Modelo': {\n",
    "        'Arquitetura': 'MobileNetV2',\n",
    "        'Transfer Learning': 'Sim (ImageNet)',\n",
    "        'Fine-tuning': 'Sim'\n",
    "    },\n",
    "    'Resultados': {\n",
    "        'Acurácia de Validação': f\"{val_accuracy:.4f}\",\n",
    "        'Precisão': f\"{val_precision:.4f}\",\n",
    "        'Recall': f\"{val_recall:.4f}\",\n",
    "        'AUC-ROC': f\"{roc_auc:.4f}\",\n",
    "        'Especificidade': f\"{specificity:.4f}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=== RESUMO DO TREINAMENTO ===\")\n",
    "for section, data in summary.items():\n",
    "    print(f\"\\n{section}:\")\n",
    "    for key, value in data.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\n=== ARQUIVOS SALVOS ===\")\n",
    "print(f\"Modelo final: {final_model_path}\")\n",
    "print(f\"Modelo (SavedModel): {savedmodel_path}\")\n",
    "print(f\"Melhor modelo fase 1: {checkpoint_path}\")\n",
    "print(f\"Melhor modelo fase 2: {checkpoint_path_fase2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Próximos Passos\n",
    "\n",
    "1. **Teste com dados independentes**: Avaliar o modelo em um conjunto de teste completamente novo\n",
    "2. **Otimização de hiperparâmetros**: Ajustar learning rate, batch size, arquitetura\n",
    "3. **Análise de erros**: Examinar casos mal classificados para entender limitações\n",
    "4. **Validação clínica**: Verificar performance com especialistas médicos\n",
    "5. **Deploy**: Preparar modelo para uso em produção\n",
    "\n",
    "**Nota**: Este modelo foi treinado para classificação binária (LSIL vs HSIL). Imagens normais/benignas foram excluídas do treinamento conforme a metodologia estabelecida."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}