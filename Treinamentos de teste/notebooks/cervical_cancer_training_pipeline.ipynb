{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports e configurações reproducíveis\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Paths (ajuste se necessário)\n",
    "ROOT = Path(r'c:/Users/IA/Desktop/citology pipeline Train')\n",
    "DATA_DIR = ROOT / 'Dataset' / 'pre-processado'\n",
    "MODELS_DIR = ROOT / 'models'\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# CSV paths\n",
    "TRAIN_CSV = DATA_DIR / 'train_data.csv'\n",
    "VAL_CSV = DATA_DIR / 'val_data.csv'\n",
    "TEST_CSV = DATA_DIR / 'test_data.csv'\n",
    "\n",
    "print('DATA_DIR =', DATA_DIR)\n",
    "print('TRAIN_CSV =', TRAIN_CSV)\n",
    "print('VAL_CSV =', VAL_CSV)\n",
    "print('TEST_CSV =', TEST_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e07f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar CSVs (verificação simples)\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "val_df = pd.read_csv(VAL_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "print('Treino:', len(train_df), 'Val:', len(val_df), 'Test:', len(test_df))\n",
    "print('Amostra das colunas do CSV:', train_df.columns.tolist())\n",
    "\n",
    "# Exemplo de caminho (para validar se relativo ou absoluto)\n",
    "sample_path = train_df.loc[0, 'image_path'] if 'image_path' in train_df.columns else None\n",
    "print('Exemplo image_path:', sample_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ed5bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros globais de treinamento\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_BASELINE = 10\n",
    "EPOCHS_ROBUST = 20\n",
    "EPOCHS_FINETUNE = 10\n",
    "INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "\n",
    "# Se os caminhos nas CSVs forem relativos ao DATA_DIR, usamos isso como root. Caso contrário, ajuste para None\n",
    "IMAGE_ROOT = DATA_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eac780d",
   "metadata": {},
   "source": [
    "## Funções utilitárias: geradores e construtor de modelo\n",
    "As funções a seguir criam geradores (com/sem augmentation) e constroem o modelo base com MobileNetV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce4104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generators(train_df, val_df, test_df, image_root=IMAGE_ROOT, augment=False, batch_size=BATCH_SIZE, img_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    \"\"\"Cria ImageDataGenerators e retorna (train_gen, val_gen, test_gen).\"\"\"\n",
    "    if augment:\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, zoom_range=0.1, horizontal_flip=True, fill_mode='nearest')\n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    common_kwargs = dict(x_col='image_path', y_col='lesion_type', target_size=img_size, class_mode='categorical')\n",
    "\n",
    "    train_gen = train_datagen.flow_from_dataframe(dataframe=train_df, directory=str(image_root) if image_root is not None else None, batch_size=batch_size, shuffle=True, **common_kwargs)\n",
    "    val_gen = val_datagen.flow_from_dataframe(dataframe=val_df, directory=str(image_root) if image_root is not None else None, batch_size=batch_size, shuffle=False, **common_kwargs)\n",
    "    test_gen = test_datagen.flow_from_dataframe(dataframe=test_df, directory=str(image_root) if image_root is not None else None, batch_size=1, shuffle=False, **common_kwargs)\n",
    "\n",
    "    return train_gen, val_gen, test_gen\n",
    "\n",
    "def build_model(input_shape=INPUT_SHAPE, num_classes=3, base_trainable=False, learning_rate=1e-4):\n",
    "    \"\"\"Constrói um MobileNetV2 com topo customizado e retorna (model, base_model)\"\"\"\n",
    "    base = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base.trainable = base_trainable\n",
    "\n",
    "    x = base.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base.input, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model, base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2d44b",
   "metadata": {},
   "source": [
    "## Função de treino genérica\n",
    "Treina um modelo recebendo callbacks e salva checkpoints/final em `.keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c8a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save(model, train_gen, val_gen, epochs, checkpoint_path, early_stop_patience=6):\n",
    "    \"\"\"Treina `model` e salva melhor checkpoint em `checkpoint_path` (.keras). Retorna (history, final_path).\"\"\"\n",
    "    os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1),\n",
    "        EarlyStopping(monitor='val_loss', patience=early_stop_patience, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(train_gen, validation_data=val_gen, epochs=epochs, callbacks=callbacks, verbose=1)\n",
    "\n",
    "    final_path = os.path.join(str(MODELS_DIR), os.path.basename(checkpoint_path).replace('.keras', '_final.keras'))\n",
    "    try:\n",
    "        best = load_model(checkpoint_path)\n",
    "        best.save(final_path)\n",
    "    except Exception as e:\n",
    "        print('Aviso: não foi possível recarregar checkpoint para salvar final:', e)\n",
    "        model.save(final_path)\n",
    "\n",
    "    return history, final_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8511dd",
   "metadata": {},
   "source": [
    "## Etapa 1 — Baseline\n",
    "Treinamento simples por um número fixo de épocas, sem augmentation, para obter uma linha de base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f42771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geradores sem augmentation (Baseline)\n",
    "train_gen, val_gen, test_gen = make_generators(train_df, val_df, test_df, image_root=IMAGE_ROOT, augment=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "num_classes = len(train_gen.class_indices)\n",
    "print('Classes detectadas:', train_gen.class_indices)\n",
    "\n",
    "# Construir modelo (base congelada)\n",
    "baseline_model, baseline_base = build_model(input_shape=INPUT_SHAPE, num_classes=num_classes, base_trainable=False, learning_rate=1e-4)\n",
    "baseline_model.summary()\n",
    "\n",
    "checkpoint_baseline = str(MODELS_DIR / 'baseline_checkpoint.keras')\n",
    "history_baseline, baseline_final_path = train_and_save(baseline_model, train_gen, val_gen, epochs=EPOCHS_BASELINE, checkpoint_path=checkpoint_baseline)\n",
    "print('Baseline final salvo em:', baseline_final_path)\n",
    "\n",
    "# Plot histórico básico\n",
    "def plot_history(history, title=''):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.legend(); plt.title(title + ' - Loss')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['accuracy'], label='acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "    plt.legend(); plt.title(title + ' - Accuracy')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history_baseline, 'Baseline')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9c91b1",
   "metadata": {},
   "source": [
    "## Etapa 2 — Treinamento Robusto\n",
    "Aplicar Data Augmentation, Transfer Learning (base congelada), callbacks e otimização simples de hiperparâmetros (busca por melhores `learning_rate`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca1bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetros candidatos (exemplo simples de busca)\n",
    "candidate_lrs = [1e-3, 1e-4, 5e-5]\n",
    "best_val_acc = -1.0\n",
    "best_model_path = None\n",
    "\n",
    "# Geradores com augmentation\n",
    "train_gen_aug, val_gen_aug, test_gen_aug = make_generators(train_df, val_df, test_df, image_root=IMAGE_ROOT, augment=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "for lr in candidate_lrs:\n",
    "    print('--- Treinando candidato lr=', lr)\n",
    "    model_candidate, _ = build_model(input_shape=INPUT_SHAPE, num_classes=num_classes, base_trainable=False, learning_rate=lr)\n",
    "    checkpoint_path = str(MODELS_DIR / f'robust_checkpoint_lr{str(lr).replace('.', 'p')}.keras')\n",
    "    history, final_path = train_and_save(model_candidate, train_gen_aug, val_gen_aug, epochs=EPOCHS_ROBUST, checkpoint_path=checkpoint_path)\n",
    "\n",
    "    # avaliar o checkpoint salvo (val_loss otimizado) - recarregar e avaliar por val_accuracy\n",
    "    try:\n",
    "        loaded = load_model(checkpoint_path)\n",
    "        res = loaded.evaluate(val_gen_aug, verbose=0)\n",
    "        val_acc = res[1] if len(res) > 1 else None\n",
    "    except Exception as e:\n",
    "        print('Falha ao carregar ou avaliar checkpoint:', e)\n",
    "        val_acc = history.history.get('val_accuracy', [None])[-1]\n",
    "\n",
    "    print('lr=', lr, ' -> val_acc=', val_acc)\n",
    "    if val_acc is not None and val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_path = checkpoint_path\n",
    "\n",
    "print('Melhor modelo da etapa 2 salvo em:', best_model_path, 'com val_acc=', best_val_acc)\n",
    "\n",
    "# Salvar cópia nomeada do melhor modelo\n",
    "if best_model_path is not None and os.path.exists(best_model_path):\n",
    "    robust_best = load_model(best_model_path)\n",
    "    robust_best_path = str(MODELS_DIR / 'robust_best.keras')\n",
    "    robust_best.save(robust_best_path)\n",
    "    print('Robust best salvo em:', robust_best_path)\n",
    "else:\n",
    "    print('Nenhum modelo válido encontrado na etapa 2.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d8ee6",
   "metadata": {},
   "source": [
    "## Etapa 3 — Fine-Tuning\n",
    "Descongelar camadas superiores da base, reduzir a taxa de aprendizado e re-treinar cuidadosamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o melhor modelo da Etapa 2 (se disponível)\n",
    "robust_best_path = str(MODELS_DIR / 'robust_best.keras')\n",
    "if os.path.exists(robust_best_path):\n",
    "    model_ft = load_model(robust_best_path)\n",
    "    print('Carregado robust_best.keras para fine-tuning')\n",
    "else:\n",
    "    fallback = str(MODELS_DIR / 'baseline_checkpoint.keras')\n",
    "    if os.path.exists(fallback):\n",
    "        model_ft = load_model(fallback)\n",
    "        print('Carregado baseline para fine-tuning (fallback)')\n",
    "    else:\n",
    "        raise FileNotFoundError('Nenhum modelo encontrado para fine-tuning. Rode a Etapa 1 ou 2 primeiro.')\n",
    "\n",
    "# Estratégia: descongelar as últimas N camadas do modelo (ajustável)\n",
    "UNFREEZE_LAST_N = 30\n",
    "total_layers = len(model_ft.layers)\n",
    "start_idx = max(0, total_layers - UNFREEZE_LAST_N)\n",
    "for i, layer in enumerate(model_ft.layers):\n",
    "    layer.trainable = True if i >= start_idx else False\n",
    "print(f'Tornadas treináveis as camadas a partir do índice {start_idx} (total {total_layers}).')\n",
    "\n",
    "# Re-compilar com LR reduzida\n",
    "FT_LR = 1e-5\n",
    "model_ft.compile(optimizer=Adam(learning_rate=FT_LR), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Preparar geradores (mantemos augmentation leve)\n",
    "train_gen_ft, val_gen_ft, test_gen_ft = make_generators(train_df, val_df, test_df, image_root=IMAGE_ROOT, augment=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "checkpoint_ft = str(MODELS_DIR / 'final_finetuned_checkpoint.keras')\n",
    "history_ft, final_ft_path = train_and_save(model_ft, train_gen_ft, val_gen_ft, epochs=EPOCHS_FINETUNE, checkpoint_path=checkpoint_ft, early_stop_patience=5)\n",
    "print('Fine-tuning final salvo em:', final_ft_path)\n",
    "plot_history(history_ft, 'Fine-Tune')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff804fae",
   "metadata": {},
   "source": [
    "## Avaliação Final e Relatórios\n",
    "Carregar o modelo final salvo e avaliar no conjunto de teste, gerando matriz de confusão e relatório de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878fcfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar modelo para avaliação: preferir fine-tuned > robust > baseline\n",
    "candidates = [str(MODELS_DIR / 'final_finetuned_checkpoint.keras'), str(MODELS_DIR / 'robust_best.keras'), str(MODELS_DIR / 'baseline_checkpoint.keras')]\n",
    "model_eval = None\n",
    "for p in candidates:\n",
    "    if os.path.exists(p):\n",
    "        print('Usando modelo para avaliação:', p)\n",
    "        model_eval = load_model(p)\n",
    "        break\n",
    "\n",
    "if model_eval is None:\n",
    "    raise FileNotFoundError('Nenhum modelo disponível para avaliação. Execute as etapas anteriores.')\n",
    "\n",
    "# Criar gerador de teste (batch_size=1 para previsões exatas)\n",
    "_, _, test_gen_eval = make_generators(train_df, val_df, test_df, image_root=IMAGE_ROOT, augment=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "print('Avaliando no conjunto de teste...')\n",
    "test_loss, test_acc = model_eval.evaluate(test_gen_eval, steps=len(test_gen_eval), verbose=1)\n",
    "print(f'Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}')\n",
    "\n",
    "# Previsões completas para relatório e matriz de confusão\n",
    "y_pred_probs = model_eval.predict(test_gen_eval, steps=len(test_gen_eval), verbose=1)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = test_gen_eval.classes\n",
    "labels = list(test_gen_eval.class_indices.keys())\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.title('Matriz de Confusão (Teste)')\n",
    "plt.show()\n",
    "\n",
    "print('Relatório de classificação (Teste):')\n",
    "print(classification_report(y_true, y_pred, target_names=labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
